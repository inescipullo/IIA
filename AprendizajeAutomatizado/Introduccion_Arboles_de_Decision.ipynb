{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_JYsY1ZYlTNs"
      },
      "source": [
        "# Técnicas de Inteligencia Artificial - Introducción a Arboles de Decisión con Python\n",
        "\n",
        "Para poder trabajar con Python de forma rápida, sencilla y desde cualquier computadora vamos a utilizar este entorno de programación llamado Google Colaboratory o, simplemente Colab, el cual es un servicio que forma parte de los servicios Cloud de Google. \n",
        "Colab está basado en los entornos Jupyter Notebooks, los cuales nos permiten escribir y ejecutar código en Python en diferentes celdas sin un orden fijo, al igual que Matlab. Además, los Notebooks de Jupyter permiten intercalar celdas de texto (como esta que estas leyendo) donde se puede complementar con información, agregar fórmulas mediante Latex, insertar imágenes o gráficas, entre otras. \n",
        "\n",
        "Para trabajar con árboles de decisión en Python vamos a utilizar la librería [SciKit-Learn](https://scikit-learn.org/stable/index.html). Esta librería implementa una gran variedad de algoritmos de aprendizaje automatizado junto con herramientas para su entrenamiento, refinamiento y validación; conjuntos de datos y algoritmos para su pre-procesamiento, entre otras. SciKit-Learn es ampliamente utilizada en ambientes científicos y de investigación, así como también en la industria principalmente debido a su potencia y simplicidad.\n",
        "\n",
        "Esta librería, al igual que muchas otras, ya se encuentran instaladas por defecto en Colab.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbZ_nO_2EIqy"
      },
      "source": [
        "## Preparación del conjunto de datos\n",
        "\n",
        "Como se mencionó anteriormente, SciKit-Learn trae incorporados varios conjuntos de datos comunmente utilizados en problemas básicos de aprendizaje automatizado. Todos ellos se encuentran en el módulo [`datasets`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.datasets) de la librería. A continuación importamos la función [`load_iris`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_iris.html#sklearn.datasets.load_iris) que permite cargar el dataset [Iris](https://archive.ics.uci.edu/ml/datasets/iris) e imprimimos algunos datos sobre el mismo.\n",
        "\n",
        "Este dataset consiste de datos correspondientes a 3 variedades de flor de Iris. Cada elemento del dataset esta representado por 4 atributos (ancho y largo del pétalo y del sépalo de la flor). En total el dataset consta de 50 ejemplos de cada una de las clases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "43epK1stlVs2"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        " \n",
        "dataset = load_iris()\n",
        "\n",
        "# Imprimo informacion para analizar el conjunto de datos\n",
        " \n",
        "print(\"Los atributos de entrada son: {}.\".format(dataset.feature_names))\n",
        "print(\"Las clases que intentaremos predecir son: {}.\".format(dataset.target_names))\n",
        "print(\"El formato de la matriz de datos es: {}.\".format(dataset.data.shape))\n",
        "print(\"El formato de la matriz de eitquetas es: {}.\".format(dataset.target.shape))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IEnwmkX6XbOI"
      },
      "source": [
        "## Conjunto de entrenamiento y evaluación\n",
        "\n",
        "Una vez cargado el dataset, podemos generar subconjuntos del mismo para el entrenamiento y evaluación del modelo. \n",
        "\n",
        "Para ello, hacemos uso de la función [`train_test_split`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html#sklearn.model_selection.train_test_split) del módulo [`model_selection`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qh4ClsGrbv9q"
      },
      "outputs": [],
      "source": [
        "# Divido los datos en conjunto de entrenamiento y evaluacion\n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "data_train, data_test, target_train, target_test = train_test_split(dataset.data,\n",
        "                                                                    dataset.target,\n",
        "                                                                    test_size = 0.2)\n",
        " \n",
        "print(\"Ahora, el conjunto de entrenamiento tiene {} muestras y el de evaluación tiene {} muestras.\".format(data_train.shape[0], data_test.shape[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qy6MnhCZPKnt"
      },
      "source": [
        "## Arbol de Decisión\n",
        "\n",
        "Para crear, entrenar y evaluar un árbol de decisión utilizamos la clase [`DecisionTreeClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) del módulo [`tree`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier). Al momento de crear el árbol, la función nos permite configurar distintos parámetros, entre los que se encuentran:\n",
        "\n",
        "*  `criterion`: Cadena de texto que puede tomar dos valores: `\"gini\"` o `\"entropy\"`. Este parámetro establece el criterio de optimización para determinar cual sera el atributo a utilizar para dividir un nodo y su valor de corte.\n",
        "*  `max_depth`: Número entero indicando la profundidad máxima que puede adoptar el árbol. Si se lo deja en `None` el árbol se expandira hasta que todas las hojas sean puras, o hasta que todas las hojas contengan menos muestras que `min_samples_leaf`.\n",
        "*  `min_samples_split`: Número entero indicando la cantidad mínima de muestras necesaria para dividir un nodo en dos nuevos nodos y/o hojas.\n",
        "*  `min_samples_leaf`: Número entero indicando la cantidad mínima de ejemplos necesaria para formar un nodo hoja. Se va a considerar la separación de un nodo en hojas solo si quedan, al menos `min_samples_leaf` ejemplos de entrenamiento, en cada una de las ramas que se derivan.\n",
        "*  `max_leaf_nodes`: Número entero indicando la cantidad máxima de hojas que puede tener el árbol.\n",
        "\n",
        "Mediante estos parámetros somos capaces de controlar las reglas de parada en el entrenamiento del modelo, con el fin de evitar el sobreentrenamiento del mismo. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcIqntNr_o8i"
      },
      "outputs": [],
      "source": [
        "# Definicion de parametros para el entrenamiento del arbol de decision\n",
        "criterion = 'gini'\n",
        "max_depth = None\n",
        "min_samples_split = 2\n",
        "min_samples_leaf = 1\n",
        "max_leaf_nodes = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mr5xmuftbQMR"
      },
      "outputs": [],
      "source": [
        "# Creamos el modelo y lo entrenamos\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        " \n",
        "tree_model = DecisionTreeClassifier(criterion = criterion,\n",
        "                                    splitter = \"best\",\n",
        "                                    max_depth = max_depth,\n",
        "                                    min_samples_leaf = min_samples_leaf,\n",
        "                                    min_samples_split = min_samples_split,\n",
        "                                    max_leaf_nodes = max_leaf_nodes)\n",
        " \n",
        "# Utilizamos el conjunto de datos de entrenamiento\n",
        " \n",
        "tree_model.fit(data_train, target_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYhR8npjhmCI"
      },
      "source": [
        "## Graficar la estructura del árbol\n",
        "\n",
        "Para poder graficar el árbol obtenido, su estructura de ramas y hojas, y algunos valores obtenidos luego del entrenamiento, tenemos dos opciones:\n",
        "\n",
        "1.   Utilizar la función [`plot_tree`](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html#sklearn.tree.plot_tree) del mismo modulo `tree`.\n",
        "2.   Utilizar la función `graph_tree` implementada a continuación.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bk3-x2KEoV3c"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import plot_tree\n",
        " \n",
        "_ = plot_tree(tree_model, feature_names=dataset.feature_names, class_names=dataset.target_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5v5rwguGskC"
      },
      "outputs": [],
      "source": [
        "import graphviz\n",
        "from sklearn import tree\n",
        " \n",
        "# Funcion para generar en gráfico del arbol.\n",
        " \n",
        "# NOTA: Para reutilizar esta funcion en otro Notebook hay que importar los mismos paquetes que se\n",
        "# importan en esta celda.\n",
        "def graph_tree(tree_model, feature_names=None, class_names=None):\n",
        " \n",
        "  dot_data = tree.export_graphviz(tree_model, out_file=None,\n",
        "                                  feature_names=feature_names,\n",
        "                                  class_names=class_names,\n",
        "                                  filled=True,\n",
        "                                  rounded=True,\n",
        "                                  special_characters=True)  \n",
        " \n",
        "  graph = graphviz.Source(dot_data)\n",
        "  return graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PSpnZn78X75G"
      },
      "outputs": [],
      "source": [
        "graph = graph_tree(tree_model, dataset.feature_names, dataset.target_names)\n",
        "graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74_yUzwofoeB"
      },
      "source": [
        "## Evaluación\n",
        "Para evaluar la performance del modelo entrenado sobre los datos vamos a utilizar la métrica de accuracy, definida por la siguiente expresión:\n",
        "\n",
        "$accuracy(y,\\hat y)=\\frac {1}{n_{samples}} \\displaystyle\\sum_{i=0}^{n_{samples}-1}1(\\hat y_i=y_i)$\n",
        "\n",
        "Donde $\\hat y_i$ es el valor predicho en la $i$_esima muestra y $y_i$ es el valor correcto que se debe predecir.\n",
        "\n",
        "Podemos calcular esta métrica mediante la función [`accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score) del módulo [`metrics`](https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics). Para ello haremos una predicción, con el modelo ya entrenado, sobre los datos del conjunto de evaluación."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XyPBQWxulMb2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Utilizo el conjunto de evaluación data_test para predecir mediante el arbol ya entrenado\n",
        "target_predicted = tree_model.predict(data_test)\n",
        "\n",
        "# Calculo el valor de accuracy obtenido\n",
        "accuracy = accuracy_score(target_test, target_predicted)\n",
        "\n",
        "print(\"El valor de accuracy obtenido es: {}\".format(accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LM4mo4LRzEbG"
      },
      "source": [
        "Pero, ¿Qué pasa si evalúo el mismo árbol sobre el conjunto de entrenamiento?..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiB3mBNM6TBN"
      },
      "source": [
        "## Sobreentrenamiento\n",
        "\n",
        "El sobreentrenamiento (overfitting) es el mayor obstáculo a la hora de entrenar un árbol de decisión, y casi cualquier modelo en aprendizaje automatizado. Si los hiperparametros no se ajustan correctamente el árbol crecerá excesivamente, lo cual puede resultar en un 100% de precisión sobre el conjunto de datos de entrenamiento, siendo el peor de los casos aquel en el que cada observación de dicho conjunto genere una hoja propia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lEaENxBFkpew"
      },
      "outputs": [],
      "source": [
        "# Chequeamos si el árbol esta sobreentrenado evaluandolo con algunos datos del conjunto de entrenamiento\n",
        "\n",
        "target_predicted = tree_model.predict(data_train)\n",
        "\n",
        "train_accuracy = accuracy_score(target_train, target_predicted)\n",
        "\n",
        "print(\"El valor de accuracy obtenido es: {}\".format(train_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jMQmQFIi7Aw"
      },
      "source": [
        "### Ajustar las restricciones (pre-prunning)\n",
        "\n",
        "Una de las formas en las que se puede evitar el sobreentrenamiento de estos modelos es mediante el ajuste minusioso de sus hiperparametros, de forma tal que limiten el crecimiento del árbol y, por lo tanto, su sobreentrenamiento. \n",
        "\n",
        "Algunos ejemplos de limitaciones podrían ser:\n",
        "\n",
        "*   Reducir la profundidad máxima que puede alcanzar.\n",
        "*   Aumentar la cantidad de observaciones necesarias para que un nodo se pueda considerar como hoja.\n",
        "*   Reducir la cantidad máxima de hojas que puede generar el árbol\n",
        "*   Aumentar la cantidad de observaciones necesarias para que un nodo pueda separarse en dos nuevos nodos/hojas.\n",
        "\n",
        "\n",
        "### Poda (post-prunning)\n",
        "\n",
        "La forma mas comun y efectiva de combatir el sobreentrenamiento en los árboles de decisión es la poda. El proceso de poda de un árbol de decisión consiste en eliminar subsecciones del mismo, transformandolas en nodos hojas que representen la clase mas común de los ejemplos de entrenamiento mas utilizados en esa subsección. Se considera, entonces, que las subsecciones eliminadas no representaban información critica, por lo que no permitian la generalización del conocimiento por parte del modelo.\n",
        "\n",
        "A continuación se implementa una función de poda, cuyo funcionamiento es similar a la de Matlab. A esta función se le pasa como argumento el modelo de árbol que se desea podar y la cantidad de niveles que se le quieren sacar y devolverá el árbol podado.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nCxqz2K4i-Ld"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree._tree import TREE_LEAF\n",
        "from copy import deepcopy\n",
        "\n",
        "# Funcion para podar un árbol.\n",
        "\n",
        "# NOTA: Para reutilizar esta función en otra Notebook hay que importar los mismos paquetes que se\n",
        "# importan en esta celda.\n",
        "\n",
        "def is_leaf(tree_model, node_id):\n",
        "  \"\"\"\n",
        "  Devuelve True si el nodo (node_id), pasado como\n",
        "  argumento, es un nodo hoja del arbol (tree_model).\n",
        "  Caso contrario retorna False.\n",
        "  \"\"\"\n",
        "  return (tree_model.tree_.children_left[node_id] == TREE_LEAF and \n",
        "          tree_model.tree_.children_right[node_id] == TREE_LEAF)\n",
        "\n",
        "\n",
        "def prune(tree_model, levels=1):\n",
        "  \"\"\"\n",
        "  Realiza la poda del arbol pasado como argumento, de forma recursiva, eliminando niveles del mismo.\n",
        "\n",
        "  Esta funcion replica el funcionamiento de su correspondiente par en Matlab:\n",
        "\n",
        "          prune(tree_model, 'level', levels)\n",
        "  \"\"\"\n",
        "  tree_model_copy = deepcopy(tree_model)\n",
        "\n",
        "  def recursive(tree_model, node_id):\n",
        "\n",
        "    if (is_leaf(tree_model, tree_model.tree_.children_left[node_id]) and\n",
        "        is_leaf(tree_model, tree_model.tree_.children_right[node_id])):\n",
        "      tree_model.tree_.children_left[node_id] = TREE_LEAF\n",
        "      tree_model.tree_.children_right[node_id] = TREE_LEAF\n",
        "    \n",
        "    if tree_model.tree_.children_left[node_id] != TREE_LEAF:\n",
        "      recursive(tree_model, tree_model.tree_.children_left[node_id])\n",
        "      recursive(tree_model, tree_model.tree_.children_right[node_id])\n",
        "      \n",
        "    return tree_model\n",
        "  \n",
        "  for _ in range(levels):\n",
        "    tree_model_copy = recursive(tree_model_copy, 0)\n",
        "\n",
        "  return tree_model_copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2iYrGBvFvSW"
      },
      "outputs": [],
      "source": [
        "# Podo el árbol y lo grafico nuevamente\n",
        "pruned_tree_model = prune(tree_model, 2)\n",
        "\n",
        "graph = graph_tree(pruned_tree_model, dataset.feature_names, dataset.target_names)\n",
        "graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ln_5CeS9GQad"
      },
      "source": [
        "Una vez podado el árbol, reevaluo con ambos conjuntos de datos para corrobar si el sobreentrenamiento se corregido."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJRYW1hZGfMl"
      },
      "outputs": [],
      "source": [
        "# Chequeamos si el árbol esta sobreentrenado evaluandolo con algunos datos del conjunto de entrenamiento\n",
        "\n",
        "target_predicted = pruned_tree_model.predict(data_test)\n",
        "\n",
        "test_accuracy = accuracy_score(target_test, target_predicted)\n",
        "\n",
        "print(\"El valor de accuracy obtenido en el conjunto de evaluacion es: {}\".format(test_accuracy))\n",
        "\n",
        "target_predicted = pruned_tree_model.predict(data_train)\n",
        "\n",
        "train_accuracy = accuracy_score(target_train, target_predicted)\n",
        "\n",
        "print(\"El valor de accuracy obtenido en el conjunto de entrenamiento es: {}\".format(train_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hc2AL6kTl6c0"
      },
      "source": [
        "## Análisis de Hiperparametros\n",
        "\n",
        "Una forma simple pero efectiva de analizar como se comporta un modelo ante distintos valores de un cierto hiperparametro consiste en entrenar varias veces el mismo modelo, variando el hiperparametro que se desea analizar, y graficando el comportamiento el modelo luego de cada entrenamiento, en funcion del valor del hiperparametro utilizado. \n",
        "\n",
        "En la siguiente celda de código se entranará un árbol de decisíon variando el valor de `min_samples_split` desde 2 hasta 10, y se graficará el valor de accuracy obtenido sobre el conjunto de testeo, en función de los asignados a `min_samples_split`.\n",
        "\n",
        "Para poder generar una gráfica utilizamos la función [`plot`](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html) de la librería [matplotlib](https://matplotlib.org/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6GbuQiim0Lp"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from matplotlib.pyplot import plot, show\n",
        "\n",
        "\n",
        "min_samples_split_values = list(range(2, 10))\n",
        "accuracy_values = []\n",
        "\n",
        "for value in min_samples_split_values:\n",
        "\n",
        "  tree_model = DecisionTreeClassifier(min_samples_split = value)\n",
        "  tree_model.fit(data_train, target_train)\n",
        "  predicted_values = tree_model.predict(data_test)\n",
        "  accuracy = accuracy_score(target_test, predicted_values)\n",
        "\n",
        "  accuracy_values.append(accuracy)\n",
        "\n",
        "\n",
        "plot(min_samples_split_values, accuracy_values)\n",
        "show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRaIWTbDE7aZ"
      },
      "source": [
        "## Validación Cruzada\n",
        "\n",
        "La validación cruzada (o cross validation) es una técnica ampliamente utilizada en el entrenamiento de modelos de aprendizaje automatizado, que sirve para evaluar la performance de dicho modelo. La forma mas utilizada de validacion cruzada es la de tipo K-Fold. La misma consiste en subdivir el conjunto de entrenamiento en K particiones y repetir el proceso de entrenamiento y evaluación K veces, dejando siempre una partición distinta para la evaluación y entrenando con el resto. El valor final de precisión del modelo será, entonces, el promedio de los valores de precisión obtenidos en cada entrenamiento.\n",
        "\n",
        "![grid_search_cross_validation.png](https://scikit-learn.org/stable/_images/grid_search_cross_validation.png)\n",
        "\n",
        "Para poder implementar validación cruzada de tipo K-Fold con SciKit-Learn debemos utilizar la función [`cross_validate`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.cross_validate.html#sklearn.model_selection.cross_validate) del modulo [`model_selection`](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q-oPzxuCE6Id"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "K = 10\n",
        "\n",
        "tree_model = DecisionTreeClassifier()\n",
        "\n",
        "score = cross_validate(tree_model, dataset.data, dataset.target, cv = K)\n",
        "\n",
        "print(\"El valor de accuracy obtenido en el conjunto de datos es: {}\".format(score[\"test_score\"].mean()))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Introduccion Arboles de Decision.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
